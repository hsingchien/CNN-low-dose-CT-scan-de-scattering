{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-dose CT scan image de-scattering\n",
    "\n",
    "## Intro\n",
    "High-dose CT scan produces high-quality images, but might bring undesired radioactive side effect on patients' health. Low-dose CT scan is safer, but the image quality is worse. One way to deal with this trade-off is to de-scatter the low-dose CT image. The process is very much like denoising, except that the 'noise' we deal here is the scattering. Here I present a solution for de-scattering using 3D CNN autoencoder. I do not own the data, so I will present this solution without the data. The idea can be applied to other similar denoising problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Volumetric CT scan image from 63 patients. Each volumetric image is 256 x 256 x 95, float32, in '.dat' format. Each patient has a scattered image and a non-scattered image (as ground-truth). \n",
    "Training set consists images from 63 patients.\n",
    "Testing set consists images from 3 patients.\n",
    "Example image is shown below:  \n",
    "<img style=\"float:left;\" src='sample/sample_img.jpg'/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN autoencoder solution\n",
    "I built a 3D CNN autoencoder to capture the feature of the image, and then use deconvolutional layers to reconstruct the image. The reason for using 3D CNN rather than 2D CNN is that the scattering is not independent over layers and I wish to capture and utilize the information on z-axis. To minimize the workload, instead of mapping a scattered image to its ground-truth counterpart, I trained the autoencoder to map the scattered image to the scattering residual. The scattering residual is simply the difference between ground truth image and scattered image.\n",
    "The architecture of the CNN is shown below. It's a fairly simple one, with only 3 convolutional layers of which kernel sizes are 9,3,5 respectively. Batch normalization is added after each convolutional layer and deconvolutional layer, and is not shown in the figure. \n",
    "<img style=\"float:left;\" src='CNN arch.jpg'/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation on Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#################### custom image data generator ###################\n",
    "####################################################################\n",
    "import numpy as np\n",
    "import keras\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, labels, batch_size=4, dim=(256,256,96), n_channels=1, n_classes=None, shuffle=True, sess='train'):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.sess = sess\n",
    "        self.n = len(list_IDs)\n",
    "        ## test git ##\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            if self.sess == 'train':\n",
    "                x_temp = np.reshape(np.fromfile('Training_dataset/' + ID + '_Sca.dat', dtype='float32'), (256,256,95), 'F')\n",
    "                y_temp = np.reshape(np.fromfile('Training_dataset/' + ID + '.dat', dtype='float32'), (256,256,95), 'F')\n",
    "            else:\n",
    "                x_temp = np.reshape(np.fromfile('Testing_dataset/' + ID + '_Sca.dat', dtype='float32'), (256,256,95), 'F')\n",
    "                y_temp = np.reshape(np.fromfile('Testing_dataset/' + ID + '.dat', dtype='float32'), (256,256,95), 'F')\n",
    "            x_temp = np.concatenate((x_temp, np.zeros((256,256,1), dtype='float32')), axis=2)\n",
    "            X[i,] = np.expand_dims(x_temp, axis=3)\n",
    "            y_temp = np.concatenate((y_temp, np.zeros((256,256,1), dtype='float32')), axis=2)\n",
    "            y[i,] =  np.expand_dims(y_temp, axis=3)# - np.expand_dims(x_temp, axis=3)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ID of training samples\n",
    "# Scattered files ends with '_Sca'\n",
    "# Ground truth files has no suffix in file name\n",
    "import os\n",
    "training_dir = 'Training_dataset/'\n",
    "file_list = os.listdir(training_dir)\n",
    "training_IDs = []\n",
    "for i in file_list:\n",
    "    if ('Sca' not in i):\n",
    "        ID = i.split('.')[0]\n",
    "        if(os.path.isfile(training_dir + '/' + ID + '_Sca'+'.dat')):\n",
    "            training_IDs.append(ID)\n",
    "\n",
    "# Generate ID of testing samples\n",
    "testing_IDs = []\n",
    "testing_list = 'Testing_dataset/'\n",
    "file_list = os.listdir(testing_list)\n",
    "for i in file_list:\n",
    "    if 'Sca' not in i:\n",
    "        ID = i.split('.')[0]\n",
    "        testing_IDs.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generators\n",
    "from keras.models import Sequential\n",
    "params = {\n",
    "    'dim': (256,256,96),\n",
    "    'batch_size': 2,\n",
    "    'n_classes': None,\n",
    "    'n_channels': 1,\n",
    "    'shuffle': True\n",
    "}\n",
    "training_generator = DataGenerator(training_IDs, None, sess='train', **params)\n",
    "testing_generator = DataGenerator(testing_IDs, None, sess='test', **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#################### build 3D CNN autoencoder ######################\n",
    "####################################################################\n",
    "from keras.layers import Input, Dense, Conv3D, UpSampling3D, MaxPooling3D, Conv3DTranspose, BatchNormalization\n",
    "from keras.models import Model\n",
    "input_img = Input(shape=(256,256,96,1))\n",
    "x = Conv3D(16, (9,9,3), activation='relu',padding='same')(input_img)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2), padding='same')(x)\n",
    "x = Conv3D(32, (3,3,3), activation='relu',padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2), padding='same')(x)\n",
    "x = Conv3D(64, (5,5,3), activation='relu',padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "encoded = MaxPooling3D(pool_size=(2,2,2), padding='same')(x)\n",
    "x = Conv3DTranspose(64, (5,5,3), activation='relu',padding='same')(encoded)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = UpSampling3D((2,2,2))(x)\n",
    "x = Conv3DTranspose(32, (3,3,3), activation='relu',padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = UpSampling3D((2,2,2))(x)\n",
    "x = Conv3DTranspose(16, (9,9,3), activation='relu',padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = UpSampling3D((2,2,2))(x)\n",
    "decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid',padding='same')(x)\n",
    "\n",
    "denoiser = Model(input_img, decoded)\n",
    "denoiser.compile(optimizer='adadelta', loss='mse')\n",
    "denoiser.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#################### train 3D CNN autoencoder ######################\n",
    "####################################################################\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "\n",
    "history = denoiser.fit_generator(\n",
    "    generator=training_generator,\n",
    "    epochs=3,\n",
    "    steps_per_epoch=training_generator.n/training_generator.batch_size,\n",
    "    validation_data = testing_generator,\n",
    "    validation_steps = testing_generator.n/testing_generator.batch_size,\n",
    "    callbacks = [tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "<img style=\"float:left;\" src='result1.jpg'/>\n",
    "The training result after 25 epochs is shown above. MSE loss of training and testing set is plotted in log scale. Loss is still decreasing at this point. On right is the predicted scattering and predicted de-scattered image. This model learned pattern of scattering near the edge of the image. Root mean square error of this testing sample decreased from 0.0232 to 0.0102. More training epochs would make more improvement. \n",
    "\n",
    "## Discussion\n",
    "This model is fairly simple, yet after 25 epochs it already captures some grand feature of the scatter, like the scatter near the edges. A more complicated model would almost certainly perform better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}